{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g28Sh8ts3GGS"
      },
      "outputs": [],
      "source": [
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pre = pd.read_csv('/content/INGRESO .csv', header = 0)\n",
        "df_his = pd.read_csv('/content/MasterData', header = 0)"
      ],
      "metadata": {
        "id": "7CjNpB0j3XhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tratamiento data historica**"
      ],
      "metadata": {
        "id": "O0EaSRvMK2A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se arregla el formato del mes para poder usarlo en documento de historicos\n",
        "df_his_mes = df_his[df_his['MesD'] != 'Anual']\n",
        "df_his_mes = df_his_mes.astype({'Mes': int})\n"
      ],
      "metadata": {
        "id": "7y8goEL_M2nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#eliminación columnas innecesarias del historico\n",
        "df_his_li = df_his_mes.drop(columns = [\"No.\",\"Departamento\",\"Municipio\",\"Region \",\"Latitud\",\"Longitud\",\"Altitud MSNM\",\"Elevación\",\"MesD\",\"Instrumento\",\"Código de instrumento\",\"Jerarquia de humedad\",\"Jerarquía de temperatura\",\"Tipo de distribución de lluvia\",\"Tipo de variación de la temp\",\"Observador actual\",\"Código de observador \",\"Edad\",\"Caracteristicas fícas de la estación\",\"Dicultad para el obervador(1 a 10)\",\"Comentarios\",\"Unnamed: 52\"])\n",
        "\n",
        "#PARA MIN\n",
        "#Headers para min de historico\n",
        "headers_min = ['Mes',\n",
        "               'Estacion',\n",
        "               'ID ESTACIONES',\n",
        "               'MIN_brillo_solar_total_total/Hrs',\n",
        "               'MIN_direccion_viento',\n",
        "               'MIN_evaporacion_piche_total ',\n",
        "               'MIN_evaporacion_tanque_total',\n",
        "               'MIN_humedad_relativa_promedio',\n",
        "               'MIN_nubosidad',\n",
        "               'MIN_precipitacion_total_mm',\n",
        "               'MIN_presion_atmosferica',\n",
        "               'MIN_radiacion',\n",
        "               'MIN_temp_max_oC',\n",
        "               'MIN_temp_min_oC',\n",
        "               'MIN_temp_suelo',\n",
        "               'MIN_temperatura_media_oC',\n",
        "               'MIN_velocidad_viento']\n",
        "\n",
        "\n",
        "#Creación de Tabla Min Historico\n",
        "df_his_min = df_his_li[headers_min]\n",
        "\n",
        "#cambio nombre MIN Historico igual al de Data Cruda\n",
        "df_his_min = df_his_min.rename({\n",
        "               'MIN_brillo_solar_total_total/Hrs':'BRILLO SOLAR',\n",
        "               'MIN_direccion_viento':'DIR. VIENTO',\n",
        "               'MIN_evaporacion_tanque_total':'EVA. TANQUE',\n",
        "               'MIN_evaporacion_piche_total ':'EVA. PICHE',\n",
        "               'MIN_humedad_relativa_promedio':'HUMEDAD REL.',\n",
        "               'MIN_nubosidad':'NUBOSIDAD',\n",
        "               'MIN_precipitacion_total_mm':'LLUVIA',\n",
        "               'MIN_presion_atmosferica':'PRESION ATM.',\n",
        "               'MIN_radiacion':'RADIACION',\n",
        "               'MIN_temp_max_oC':'TMAX',\n",
        "               'MIN_temp_min_oC':'TMIN',\n",
        "               'MIN_temp_suelo':'TSUELO',\n",
        "               'MIN_temperatura_media_oC':'TMED',\n",
        "               'MIN_velocidad_viento':'VEL. VIENTO'}, axis='columns')\n",
        "\n",
        "\n",
        "\n",
        "#Transposicion de columnas MIN Historico\n",
        "df_his_min_unpivot = pd.melt(df_his_min, id_vars = [\"Mes\", \"Estacion\", \"ID ESTACIONES\"], value_vars = ['BRILLO SOLAR',\n",
        "               'DIR. VIENTO',\n",
        "               'EVA. PICHE',\n",
        "               'EVA. TANQUE',\n",
        "               'NUBOSIDAD',\n",
        "               'HUMEDAD REL.',\n",
        "               'LLUVIA',\n",
        "               'PRESION ATM.',\n",
        "               'RADIACION',\n",
        "               'TMAX',\n",
        "               'TMIN',\n",
        "               'TSUELO',\n",
        "               'TMED',\n",
        "               'VEL. VIENTO'])\n",
        "\n",
        "#cambio nombre variable columna MIN Historico\n",
        "df_his_min_unpivot.rename(columns = {'value':'rango_min'}, inplace = True)\n",
        "\n",
        "#PARA MAX\n",
        "#Header MAX Historico\n",
        "headers_max = ['Mes', \n",
        "               'Estacion',\n",
        "               'ID ESTACIONES',\n",
        "               'MAX _brillo_solar_total_total/Hrs',\n",
        "               'MAX _temp_max_oC', \n",
        "               'MAX_direccion_viento',\n",
        "               'MAX_evaporacion_piche_total ',\n",
        "               'MAX_evaporacion_tanque_total ',\n",
        "               'MAX_humedad_relativa_promedio ', \n",
        "               'MAX_nubosidad',\n",
        "               'MAX_precipitacion_total_mm',\n",
        "               'MAX_presion_atmosferica',\n",
        "               'MAX_radiacion',\n",
        "               'MAX_temp_media_oC',\n",
        "               'MAX_temp_min_oC',\n",
        "               'MAX_temp_suelo',\n",
        "               'MAX_velocidad_viento']\n",
        "\n",
        "#Creación de MAX Historico\n",
        "df_his_max = df_his_li[headers_max]\n",
        "\n",
        "#cambio nombre columnas MAX Historico\n",
        "df_his_max = df_his_max.rename({\n",
        "               'MAX _brillo_solar_total_total/Hrs':'BRILLO SOLAR',\n",
        "               'MAX _temp_max_oC':'TMAX',\n",
        "               'MAX_direccion_viento':'DIR. VIENTO',\n",
        "               \n",
        "               'MAX_evaporacion_tanque_total ':'EVA. TANQUE',\n",
        "               'MAX_evaporacion_piche_total ':'EVA. PICHE',\n",
        "               'MAX_humedad_relativa_promedio ':'HUMEDAD REL.',\n",
        "               'MAX_nubosidad':'NUBOSIDAD',\n",
        "               'MAX_precipitacion_total_mm':'LLUVIA',\n",
        "               'MAX_presion_atmosferica':'PRESION ATM.',\n",
        "               'MAX_radiacion':'RADIACION',\n",
        "               'MAX_temp_media_oC':'TMED',\n",
        "               'MAX_temp_min_oC':'TMIN',\n",
        "               'MAX_temp_suelo':'TSUELO',\n",
        "               'MAX_velocidad_viento':'VEL. VIENTO'}, axis='columns')\n",
        "\n",
        "#Trasposicion de columnas MAX Historico\n",
        "df_his_max_unpivot = pd.melt(df_his_max, id_vars = [\"Mes\", \"Estacion\", \"ID ESTACIONES\"], value_vars = ['BRILLO SOLAR',\n",
        "               'DIR. VIENTO',\n",
        "               'EVA. PICHE',\n",
        "               'EVA. TANQUE',\n",
        "               'NUBOSIDAD',\n",
        "               'HUMEDAD REL.',\n",
        "               'LLUVIA',\n",
        "               'PRESION ATM.',\n",
        "               'RADIACION',\n",
        "               'TMAX',\n",
        "               'TMIN',\n",
        "               'TSUELO',\n",
        "               'TMED',\n",
        "               'VEL. VIENTO'])\n",
        "\n",
        "#cambio nombre variable columna MAX Historico\n",
        "df_his_max_unpivot.rename(columns = {'value':'rango_max' }, inplace = True)\n",
        "\n",
        "#Unión df_his_max_unpivot + df_his_min_unpivot\n",
        "df_his_comp = df_his_min_unpivot.merge(df_his_max_unpivot, how = 'left', on = ['Mes','ID ESTACIONES','variable'])\n",
        "\n"
      ],
      "metadata": {
        "id": "DM8DYLOiK2Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ver si elimino los nan y las estaciones quedandome con el ID\n",
        "df_his_comp_na = df_his_comp.dropna()\n"
      ],
      "metadata": {
        "id": "vcV9h3x08DTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tratamiento Data Preliminar **"
      ],
      "metadata": {
        "id": "xxfNCtljb5aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pre.head()\n",
        "df_pre.info()"
      ],
      "metadata": {
        "id": "SvetZuuT6S6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eliminación del encabezado innecesario\n",
        "df_pre = df_pre.drop([1, 0],axis=0)\n"
      ],
      "metadata": {
        "id": "xrv55D_3_kQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cambio de nombre de la columna de fecha\n",
        "df_pre = df_pre.rename(columns = {'Unnamed: 0': 'FECHA'})\n",
        "\n",
        "df_pre.head()"
      ],
      "metadata": {
        "id": "PKhRYZGmB5Y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convertir columna de fecha en el formato correcto\n",
        "df_pre_fecha = df_pre[df_pre['FECHA'].notnull()]\n",
        "df_pre_fecha['Fecha'] = pd.to_datetime(df_pre_fecha['FECHA']).dt.strftime('%d/%m/%Y')\n",
        "df_pre_fecha['FechaD'] = pd.to_datetime(df_pre_fecha['FECHA'])\n",
        "#extraccion en columna a parte el mes\n",
        "df_pre_fecha['Mes'] = df_pre_fecha['FechaD'].dt.month\n",
        "df_pre_fecha['Mes'] = df_pre_fecha['Mes'].astype(int)\n",
        "\n",
        "df_pre_fecha.head()\n",
        "#df_pre_fecha.info()"
      ],
      "metadata": {
        "id": "EYRJq0JIqMma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transposición del ID Estaciones a filas \n",
        "df_pre_fecha_unpivot = pd.melt(df_pre_fecha, id_vars = ['Mes',\"FECHA\", \"VARIABLE\"], value_vars = [ 'INS200501CV',\n",
        "               'INS121601CV',\n",
        "               'INS110701CV',\n",
        "               'INS160101CV',\n",
        "               'INS071301CV',\n",
        "               'INS200701CV',\n",
        "               'INS170101CV',\n",
        "               'INS010102CV',\n",
        "               'INS210601CV',\n",
        "               'INS190201CV',\n",
        "               'INS090301CV',\n",
        "               'INS090101CV',\n",
        "               'INS100101CV',\n",
        "               'INS221401CV',\n",
        "               'INS160701CV',\n",
        "               'INS180101CV',\n",
        "               'INS110101CV',\n",
        "               'INS141601CV',\n",
        "               'INS120101CV',\n",
        "               'INS041001CV',\n",
        "               'INS131501CV',\n",
        "               'INS010101CV',\n",
        "               'INS040101CV',\n",
        "               'INS220501CV',\n",
        "               'INS-140301',\n",
        "               'INS070101CV',\n",
        "               'INS130101CV',\n",
        "               'INS190901CV',\n",
        "               'INS180201CV',\n",
        "               'INS141301CV',\n",
        "               'INS171201CV',\n",
        "               'INS221701CV',\n",
        "               'INS050101CV',\n",
        "               'INS020302CV',\n",
        "               'INS150701CV',\n",
        "               'INS050901CV',\n",
        "               'INS130601CV',\n",
        "               'INS161201CV',\n",
        "               'INS071901CV',\n",
        "               'INS030801CV',\n",
        "               'INS121701CV',\n",
        "               'INS141901CV',\n",
        "               'INS150401CV',\n",
        "               'INS020301CV',\n",
        "               'INS060101CV',\n",
        "               'INS190301CV',\n",
        "               'INS210101CV',\n",
        "               'INS040301CV',\n",
        "               'INS011401AT',\n",
        "               'INS030101AT',\n",
        "               'INS050101AT',\n",
        "               'INS122301AT',\n",
        "               'INS210101AT',\n",
        "               'INS122101AT',\n",
        "               'INS-010331',\n",
        "               'INS010801AT',\n",
        "               'INS180501AT',\n",
        "               'INS180401AT',\n",
        "               'INS-130527',\n",
        "               'PLUVIOMÉT',\n",
        "               'INS090401AT',\n",
        "               'INS142201AT',\n",
        "               'INS010301AT',\n",
        "               'INS010701AT',\n",
        "               'INS140101AT',\n",
        "               'INS040801AT',\n",
        "               'INS080101AT'])\n",
        "df_pre_fecha_unpivot.head()"
      ],
      "metadata": {
        "id": "CFuOgJcJ7HPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#renombre de columnas segun necesidad\n",
        "df_pre_fecha_unpivot = df_pre_fecha_unpivot.rename(columns = {'variable': 'ID ESTACIONES'})\n",
        "df_pre_fecha_unpivot = df_pre_fecha_unpivot.rename(columns = {'VARIABLE': 'variable'})\n",
        "df_pre_fecha_unpivot.head()"
      ],
      "metadata": {
        "id": "NlE6_W2vGf9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reemplazo de -99.9 por NaN\n",
        "df_pre_fecha_unpivot_re = df_pre_fecha_unpivot.replace(to_replace = '-99.9', value = np.nan)\n",
        "#df_datos_preliminares_nan = df_datos_preliminares_nan.replace(to_replace = 'NR', value = np.nan) \n",
        "#df_datos_preliminares_nan = df_datos_preliminares_nan.replace(to_replace = 'R/', value = np.nan)\n",
        "\n",
        "#({'value': -99.9},np.nan)\n",
        "#df_datos_preliminares_nan_NR = df_datos_preliminares_unpivot.replace(to_replace = 'NR', value = np.nan) \n",
        "#({'value': NR},np.nan)\n",
        "df_pre_fecha_unpivot_re.head()"
      ],
      "metadata": {
        "id": "LY9oCfmxIQNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eliminacion de NAN\n",
        "df_pre_fecha_unpivot_re_na = df_pre_fecha_unpivot_re.dropna()\n"
      ],
      "metadata": {
        "id": "a-vksY15mXEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Union df_his_comp_na + df_pre_fecha_unpivot_re_na \n",
        "df_his_pre = df_pre_fecha_unpivot_re_na.merge(df_his_comp_na, how = 'left', on = ['Mes','ID ESTACIONES','variable'])\n",
        "df_his_pre.head(10)"
      ],
      "metadata": {
        "id": "JH_1w9gIKHEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eliminacion de nuevo de NA, revisar bien esto\n",
        "df_his_pre_na = df_his_pre.dropna()\n",
        "df_his_pre_na.head(30)"
      ],
      "metadata": {
        "id": "y2vTJyCAYOWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_his_pre_na.info()"
      ],
      "metadata": {
        "id": "cNSdwZpDZOxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Elimina letras en la columna de value\n",
        "df_his_pre_na['value'] = pd.to_numeric(df_his_pre_na['value'],errors='coerce')\n"
      ],
      "metadata": {
        "id": "iInVOzSCb5qX",
        "outputId": "3af30c7a-257f-4d59-efc1-13ace62ba52d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rangos y valor de variables en el mismo formato\n",
        "df_his_pre_na_fl = df_his_pre_na.astype(\n",
        "    {\n",
        "    'value': float,\n",
        "    'rango_min': float,\n",
        "    'rango_max': float,\n",
        "    }\n",
        "  )\n",
        "\n",
        "df_valida_var = df_his_pre_na_fl\n",
        "#Validacion de rango para todas las variables\n",
        "df_valida_var['value'] = np.where(\n",
        "  (df_valida_var['value'] <= df_valida_var['rango_max']) & \n",
        "  (df_valida_var['value'] >= df_valida_var['rango_min']),\n",
        "  df_valida_var['value'],\n",
        "  np.nan)\n"
      ],
      "metadata": {
        "id": "TjsQt3ACZse-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_valida_var.head(30)"
      ],
      "metadata": {
        "id": "7qnRsT_d4tjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eliminacion de NaN\n",
        "df_valida_var_na = df_valida_var.dropna()\n",
        "df_valida_var_na.head(30)\n"
      ],
      "metadata": {
        "id": "MeRqnT9ODKKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tratamiento tmax≤tmin"
      ],
      "metadata": {
        "id": "o_PpXkt9iDiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pivotear las variables\n",
        "df_valida_var_pivot = df_valida_var_na\n",
        "df_valida_var_pivot = df_valida_var_pivot.pivot_table(index = ['FECHA','ID ESTACIONES'], columns = 'variable', aggfunc = 'first')['value']\n",
        "\n",
        "df_valida_var_pivot = df_valida_var_pivot.reset_index()"
      ],
      "metadata": {
        "id": "D6i55MkdAaee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_valida_var_pivot.head()"
      ],
      "metadata": {
        "id": "IrIk9lrD9ciY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creacion de columna extra para saber si tiene NaN la variale TMAX,TMIN\n",
        "df_valida_tmax_tmin = df_valida_var_pivot\n",
        "\n",
        "\n",
        "df_valida_tmax_tmin['val_nan'] = np.where((df_valida_tmax_tmin['TMAX'].isnull()) | (df_valida_tmax_tmin['TMIN'].isnull()), 1, 0)\n"
      ],
      "metadata": {
        "id": "GTQ4oGEfGHDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Validacion de tmax < tmin \n",
        "df_valida_tmax_tmin['TMAX'] = np.where(\n",
        "                                        df_valida_tmax_tmin['val_nan'] == 0,\n",
        "                                          np.where(\n",
        "                                                    df_valida_tmax_tmin['TMAX'] <= df_valida_tmax_tmin['TMIN'], np.nan, df_valida_tmax_tmin['TMAX']\n",
        "                                          ),\n",
        "                                       df_valida_tmax_tmin['TMAX'])"
      ],
      "metadata": {
        "id": "1AcicWkQ5-Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_valida_tmax_tmin.head(100)"
      ],
      "metadata": {
        "id": "OSjWGkib_qtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eliminacion de columna de val_nan\n",
        "#Base de datos final\n",
        "df_validado = df_valida_tmax_tmin.drop(columns = [\"val_nan\"])"
      ],
      "metadata": {
        "id": "SHYcyAXhJtVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_validado.head()"
      ],
      "metadata": {
        "id": "0lQnCKCjLJmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generar documento de estadistica de QC"
      ],
      "metadata": {
        "id": "-dTWX5P0nqqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generar estadistica descriptiva de toda las variables"
      ],
      "metadata": {
        "id": "CrsaIc_Tn1CR"
      }
    }
  ]
}