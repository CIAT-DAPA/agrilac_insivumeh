{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g28Sh8ts3GGS"
      },
      "outputs": [],
      "source": [
        "import datetime as dt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas_profiling import ProfileReport\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pre = pd.read_csv('/content/INGRESO DATOS DIARIO -PRELIMINAR- - DATOS 2022.csv', header = 0)\n",
        "df_his = pd.read_csv('/content/MasterData Estaciones - MasterData.csv', header = 0)"
      ],
      "metadata": {
        "id": "7CjNpB0j3XhP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tratamiento data historica**"
      ],
      "metadata": {
        "id": "O0EaSRvMK2A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_historica (df):\n",
        "  #Se arregla el formato del mes para poder usarlo en documento de historicos\n",
        "  df_his_mes = df_his[df_his['MesD'] != 'Anual']\n",
        "  df_his_mes = df_his_mes.astype({'Mes': int})\n",
        "  #eliminación columnas innecesarias del historico\n",
        "  df_his_li = df_his_mes.drop(columns = [\"No.\",\"Departamento\",\"Municipio\",\"Region \",\n",
        "                                         \"Latitud\",\"Longitud\",\"Altitud MSNM\",\n",
        "                                         \"Elevación\",\"MesD\",\"Instrumento\",\n",
        "                                         \"Código de instrumento\",\"Jerarquia de humedad\",\n",
        "                                         \"Jerarquía de temperatura\",\"Tipo de distribución de lluvia\",\n",
        "                                         \"Tipo de variación de la temp\",\"Observador actual\",\n",
        "                                         \"Código de observador \",\"Edad\",\n",
        "                                         \"Caracteristicas fícas de la estación\",\n",
        "                                         \"Dicultad para el obervador(1 a 10)\",\n",
        "                                         \"Comentarios\",\"Unnamed: 52\"])\n",
        "\n",
        "#PARA MIN\n",
        "#Headers para min de historico\n",
        "  headers_min = ['Mes','Estacion','ID ESTACIONES',\n",
        "               'MIN_brillo_solar_total_total/Hrs',\n",
        "               'MIN_velocidad_viento',\n",
        "               'MIN_direccion_viento',\n",
        "               'MIN_evaporacion_piche_total ',\n",
        "               'MIN_evaporacion_tanque_total',\n",
        "               'MIN_humedad_relativa_promedio',\n",
        "               'MIN_nubosidad',\n",
        "               'MIN_precipitacion_total_mm',\n",
        "               'MIN_presion_atmosferica',\n",
        "               'MIN_radiacion',\n",
        "               'MIN_temp_max_oC',\n",
        "               'MIN_temp_min_oC',\n",
        "               'MIN_temp_suelo',\n",
        "               'MIN_temperatura_media_oC']\n",
        "\n",
        "\n",
        "#Creación de Tabla Min Historico\n",
        "  df_his_min = df_his_li[headers_min]\n",
        "\n",
        "#cambio nombre MIN Historico igual al de Data Cruda\n",
        "  df_his_min = df_his_min.rename({\n",
        "               'MIN_brillo_solar_total_total/Hrs':'BRILLO SOLAR',\n",
        "               'MIN_direccion_viento':'DIR. VIENTO',\n",
        "               'MIN_evaporacion_tanque_total':'EVA. TANQUE',\n",
        "               'MIN_evaporacion_piche_total ':'EVA. PICHE',\n",
        "               'MIN_humedad_relativa_promedio':'HUMEDAD REL.',\n",
        "               'MIN_nubosidad':'NUBOSIDAD',\n",
        "               'MIN_precipitacion_total_mm':'LLUVIA',\n",
        "               'MIN_presion_atmosferica':'PRESION ATM.',\n",
        "               'MIN_radiacion':'RADIACION',\n",
        "               'MIN_temp_max_oC':'TMAX',\n",
        "               'MIN_temp_min_oC':'TMIN',\n",
        "               'MIN_temp_suelo':'TSUELO',\n",
        "               'MIN_temperatura_media_oC':'TMED',\n",
        "               'MIN_velocidad_viento':'VEL. VIENTO'}, axis='columns')\n",
        "\n",
        "\n",
        "\n",
        "#Transposicion de columnas MIN Historico\n",
        "  df_his_min_unpivot = pd.melt(df_his_min, id_vars = [\"Mes\", \"Estacion\", \"ID ESTACIONES\"], \n",
        "                               value_vars = ['BRILLO SOLAR','DIR. VIENTO',\n",
        "                                             'EVA. PICHE','EVA. TANQUE',\n",
        "                                             'NUBOSIDAD','HUMEDAD REL.',\n",
        "                                             'LLUVIA','PRESION ATM.',\n",
        "                                             'RADIACION','TMAX',\n",
        "                                             'TMIN','TSUELO',\n",
        "                                             'TMED','VEL. VIENTO'])\n",
        "\n",
        "#cambio nombre variable columna MIN Historico\n",
        "  df_his_min_unpivot.rename(columns = {'value':'rango_min'}, inplace = True)\n",
        "\n",
        "#PARA MAX\n",
        "#Header MAX Historico\n",
        "  headers_max = ['Mes', \n",
        "               'Estacion',\n",
        "               'ID ESTACIONES',\n",
        "               'MAX _brillo_solar_total_total/Hrs',\n",
        "               'MAX _temp_max_oC', \n",
        "               'MAX_direccion_viento',\n",
        "               'MAX_evaporacion_piche_total ',\n",
        "               'MAX_evaporacion_tanque_total ',\n",
        "               'MAX_humedad_relativa_promedio ', \n",
        "               'MAX_nubosidad',\n",
        "               'MAX_precipitacion_total_mm',\n",
        "               'MAX_presion_atmosferica',\n",
        "               'MAX_radiacion',\n",
        "               'MAX_temp_media_oC',\n",
        "               'MAX_temp_min_oC',\n",
        "               'MAX_temp_suelo',\n",
        "               'MAX_velocidad_viento']\n",
        "\n",
        "#Creación de MAX Historico\n",
        "  df_his_max = df_his_li[headers_max]\n",
        "\n",
        "#cambio nombre columnas MAX Historico\n",
        "  df_his_max = df_his_max.rename({\n",
        "               'MAX _brillo_solar_total_total/Hrs':'BRILLO SOLAR',\n",
        "               'MAX _temp_max_oC':'TMAX',\n",
        "               'MAX_direccion_viento':'DIR. VIENTO',\n",
        "               'MAX_evaporacion_tanque_total ':'EVA. TANQUE',\n",
        "               'MAX_evaporacion_piche_total ':'EVA. PICHE',\n",
        "               'MAX_humedad_relativa_promedio ':'HUMEDAD REL.',\n",
        "               'MAX_nubosidad':'NUBOSIDAD',\n",
        "               'MAX_precipitacion_total_mm':'LLUVIA',\n",
        "               'MAX_presion_atmosferica':'PRESION ATM.',\n",
        "               'MAX_radiacion':'RADIACION',\n",
        "               'MAX_temp_media_oC':'TMED',\n",
        "               'MAX_temp_min_oC':'TMIN',\n",
        "               'MAX_temp_suelo':'TSUELO',\n",
        "               'MAX_velocidad_viento':'VEL. VIENTO'}, axis='columns')\n",
        "\n",
        "#Trasposicion de columnas MAX Historico\n",
        "  df_his_max_unpivot = pd.melt(df_his_max, id_vars = [\"Mes\", \"Estacion\", \"ID ESTACIONES\"], value_vars = ['BRILLO SOLAR',\n",
        "               'DIR. VIENTO',\n",
        "               'EVA. PICHE',\n",
        "               'EVA. TANQUE',\n",
        "               'NUBOSIDAD',\n",
        "               'HUMEDAD REL.',\n",
        "               'LLUVIA',\n",
        "               'PRESION ATM.',\n",
        "               'RADIACION',\n",
        "               'TMAX',\n",
        "               'TMIN',\n",
        "               'TSUELO',\n",
        "               'TMED',\n",
        "               'VEL. VIENTO'])\n",
        "\n",
        "#cambio nombre variable columna MAX Historico\n",
        "  df_his_max_unpivot.rename(columns = {'value':'rango_max' }, inplace = True)\n",
        "\n",
        "#Unión df_his_max_unpivot + df_his_min_unpivot\n",
        "  df_his_comp = df_his_min_unpivot.merge(df_his_max_unpivot, how = 'left', on = ['Mes','ID ESTACIONES','variable'])\n",
        "#ver si elimino los nan y las estaciones quedandome con el ID\n",
        "  df_his_comp_na = df_his_comp.dropna()\n",
        "  \n",
        "  return df_his_comp_na\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wYExrdQKR02e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_historica_procesada = data_historica(df_his)\n",
        "data_historica_procesada.head()\n"
      ],
      "metadata": {
        "id": "zmhynIeXoOtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tratamiento Data Preliminar**"
      ],
      "metadata": {
        "id": "pLncB16jSyRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preliminar (df_pre,data_historica_procesada):\n",
        "#Eliminación del encabezado innecesario\n",
        "  df_pre = df_pre.drop([1, 0],axis=0)\n",
        "#cambio de nombre de la columna de fecha\n",
        "  df_pre = df_pre.rename(columns = {'Unnamed: 0': 'FECHA'})\n",
        "#Convertir columna de fecha en el formato correcto\n",
        "  df_pre_fecha = df_pre[df_pre['FECHA'].notnull()]\n",
        "  df_pre_fecha['Fecha'] = pd.to_datetime(df_pre_fecha['FECHA']).dt.strftime('%d/%m/%Y')\n",
        "  df_pre_fecha['FechaD'] = pd.to_datetime(df_pre_fecha['FECHA'])\n",
        "#extraccion en columna a parte el mes\n",
        "  df_pre_fecha['Mes'] = df_pre_fecha['FechaD'].dt.month\n",
        "  df_pre_fecha['Mes'] = df_pre_fecha['Mes'].astype(int)\n",
        "#Transposición del ID Estaciones a filas \n",
        "  df_pre_fecha_unpivot = pd.melt(df_pre_fecha, id_vars = ['Mes',\"FECHA\", \"VARIABLE\"], value_vars = [ 'INS200501CV',\n",
        "               'INS121601CV','INS110701CV',\n",
        "               'INS160101CV','INS071301CV',\n",
        "               'INS200701CV','INS170101CV',\n",
        "               'INS010102CV','INS210601CV',\n",
        "               'INS190201CV','INS090301CV',\n",
        "               'INS090101CV','INS100101CV',\n",
        "               'INS221401CV','INS160701CV',\n",
        "               'INS180101CV','INS110101CV',\n",
        "               'INS141601CV','INS120101CV',\n",
        "               'INS041001CV','INS131501CV',\n",
        "               'INS010101CV','INS040101CV',\n",
        "               'INS220501CV','INS-140301',\n",
        "               'INS070101CV','INS130101CV',\n",
        "               'INS190901CV','INS180201CV',\n",
        "               'INS141301CV','INS171201CV',\n",
        "               'INS221701CV','INS050101CV',\n",
        "               'INS020302CV','INS150701CV',\n",
        "               'INS050901CV','INS130601CV',\n",
        "               'INS161201CV','INS071901CV',\n",
        "               'INS030801CV','INS121701CV',\n",
        "               'INS141901CV','INS150401CV',\n",
        "               'INS020301CV','INS060101CV',\n",
        "               'INS190301CV','INS210101CV',\n",
        "               'INS040301CV','INS011401AT',\n",
        "               'INS030101AT','INS050101AT',\n",
        "               'INS122301AT','INS210101AT',\n",
        "               'INS122101AT','INS-010331',\n",
        "               'INS010801AT','INS180501AT',\n",
        "               'INS180401AT','INS-130527',\n",
        "               'PLUVIOMÉT','INS090401AT',\n",
        "               'INS142201AT','INS010301AT',\n",
        "               'INS010701AT','INS140101AT',\n",
        "               'INS040801AT','INS080101AT'])\n",
        "\n",
        "#renombre de columnas segun necesidad\n",
        "  df_pre_fecha_unpivot = df_pre_fecha_unpivot.rename(columns = {'variable': 'ID ESTACIONES'})\n",
        "  df_pre_fecha_unpivot = df_pre_fecha_unpivot.rename(columns = {'VARIABLE': 'variable'})\n",
        "#reemplazo de -99.9 por NaN\n",
        "  df_pre_fecha_unpivot_re = df_pre_fecha_unpivot.replace(to_replace = '-99.9', value = np.nan)\n",
        "#Eliminacion de NAN\n",
        "  df_pre_fecha_unpivot_re_na = df_pre_fecha_unpivot_re.dropna()\n",
        "#Union df_his_comp_na + df_pre_fecha_unpivot_re_na \n",
        "  df_his_pre = df_pre_fecha_unpivot_re_na.merge(data_historica_procesada, how = 'left', on = ['Mes','ID ESTACIONES','variable'])\n",
        "#eliminacion de nuevo de NA, revisar bien esto\n",
        "  df_his_pre_na = df_his_pre.dropna()\n",
        "#Elimina letras en la columna de value\n",
        "  df_his_pre_na['value'] = pd.to_numeric(df_his_pre_na['value'],errors='coerce')\n",
        "  return df_his_pre_na"
      ],
      "metadata": {
        "id": "ynE5HiMoS5QR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_preli_procesada = data_preliminar (df_pre,data_historica_procesada)\n",
        "data_preli_procesada.head()"
      ],
      "metadata": {
        "id": "PyQtgB_kp7Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def valida_rango (data_preli_procesada):\n",
        "\n",
        "#Rangos y valor de variables en el mismo formato\n",
        "  df_his_pre_na_fl = data_preli_procesada.astype(\n",
        "    {\n",
        "    'value': float,\n",
        "    'rango_min': float,\n",
        "    'rango_max': float,\n",
        "    }\n",
        "  )\n",
        "\n",
        "  df_valida_var = df_his_pre_na_fl\n",
        "#Validacion de rango para todas las variables\n",
        "  df_valida_var['value'] = np.where(\n",
        "    (df_valida_var['value'] <= df_valida_var['rango_max']) & \n",
        "    (df_valida_var['value'] >= df_valida_var['rango_min']),\n",
        "    df_valida_var['value'],\n",
        "    np.nan)\n",
        "#Eliminacion de NaN\n",
        "  df_valida_var_na = df_valida_var.dropna()\n",
        "\n",
        "  \n",
        "\n",
        "  return df_valida_var_na"
      ],
      "metadata": {
        "id": "TjsQt3ACZse-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_valida_rango = valida_rango (data_pre_procesada)\n",
        "data_valida_rango.head()"
      ],
      "metadata": {
        "id": "tPtuRoZEqhR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tratamiento tmax≤tmin**"
      ],
      "metadata": {
        "id": "o_PpXkt9iDiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tmax_menor_tmin (data_valida_rango):\n",
        "  #pivotear las variables\n",
        "  df_valida_var_pivot = data_valida_rango\n",
        "  df_valida_var_pivot = df_valida_var_pivot.pivot_table(index = ['FECHA','ID ESTACIONES', 'Mes'], columns = 'variable', aggfunc = 'first')['value']\n",
        "\n",
        "  df_valida_var_pivot = df_valida_var_pivot.reset_index()\n",
        "\n",
        "#Creacion de columna extra para saber si tiene NaN la variale TMAX,TMIN\n",
        "  df_valida_tmax_tmin = df_valida_var_pivot\n",
        "\n",
        "  df_valida_tmax_tmin['val_nan'] = np.where((df_valida_tmax_tmin['TMAX'].isnull()) | (df_valida_tmax_tmin['TMIN'].isnull()), 1, 0)\n",
        "\n",
        "#Validacion de tmax < tmin \n",
        "  df_valida_tmax_tmin['TMAX'] = np.where(\n",
        "                                        df_valida_tmax_tmin['val_nan'] == 0,\n",
        "                                          np.where(\n",
        "                                                    df_valida_tmax_tmin['TMAX'] <= df_valida_tmax_tmin['TMIN'], np.nan, df_valida_tmax_tmin['TMAX']\n",
        "                                          ),\n",
        "                                       df_valida_tmax_tmin['TMAX'])\n",
        "\n",
        "#Eliminacion de columna de val_nan\n",
        "#Base de datos final\n",
        "  df_validado = df_valida_tmax_tmin.drop(columns = [\"val_nan\"])\n",
        "  return df_validado"
      ],
      "metadata": {
        "id": "5uDrIcaVUSjJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_base_final = tmax_menor_tmin (data_valida_rango)\n",
        "df_base_final.head()"
      ],
      "metadata": {
        "id": "dne9KHl4sM45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}